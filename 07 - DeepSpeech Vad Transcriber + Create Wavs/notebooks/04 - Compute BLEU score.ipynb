{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f595c8",
   "metadata": {},
   "source": [
    "[Links:]()\n",
    "+ [Link](https://machinelearningmastery.com/calculate-bleu-score-for-text-python/) to compute BLEU score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c70b9ac",
   "metadata": {},
   "source": [
    "### Individual N-Gram Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "810076bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual 1-gram: 0.750000\n",
      "Individual 2-gram: 0.666667\n",
      "Individual 3-gram: 0.500000\n",
      "Individual 4-gram: 0.000000\n",
      "Mean: 0.479167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/DeepSpeech/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# n-gram individual BLEU\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "candidate = 'this is a test'\n",
    "reference = 'this is a cat'\n",
    "\n",
    "def compute_bleu(candidate, reference, gram=1):\n",
    "    candidate = candidate.split(\" \")\n",
    "    reference = [reference.split(\" \")]\n",
    "    weights = [0, 0, 0, 0]\n",
    "    weights[gram - 1] = 1 \n",
    "    \"\"\"\n",
    "    print(candidate)\n",
    "    print(reference)\n",
    "    print(weights)\n",
    "    \"\"\"\n",
    "    return sentence_bleu(reference, candidate, weights=weights) \n",
    "        \n",
    "print('Individual 1-gram: %f' % compute_bleu(candidate, reference, gram=1))\n",
    "print('Individual 2-gram: %f' % compute_bleu(candidate, reference, gram=2))\n",
    "print('Individual 3-gram: %f' % compute_bleu(candidate, reference, gram=3))\n",
    "print('Individual 4-gram: %f' % compute_bleu(candidate, reference, gram=4))\n",
    "\n",
    "print(\"Mean: %f\" % (sum([compute_bleu(candidate, reference, gram=i) for i in range(4)]) / 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796445f8",
   "metadata": {},
   "source": [
    "### Cumulative N-Gram Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac013d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0547686614863434e-154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/DeepSpeech/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['this', 'is', 'small', 'test']]\n",
    "candidate = ['this', 'is', 'a', 'test']\n",
    "score = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7901bf5a",
   "metadata": {},
   "source": [
    "### Compute BLEU from metadata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "830f89d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/DeepSpeech/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/root/anaconda3/envs/DeepSpeech/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/root/anaconda3/envs/DeepSpeech/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bleu1: 0.6125758244644451\n",
      "Total bleu2: 0.73698545859529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTotal bleu1: 0.5347381994290764\\nTotal bleu2: 0.6913090188969255\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "\n",
    "meta = \"/root/PycharmProjects/Tensorflow-2.X/07 - DeepSpeech Vad Transcriber + Create Wavs/audio/Going to public places/metadata.csv\"\n",
    "\n",
    "\n",
    "\n",
    "def compute_bleu(candidate, reference, gram=1):\n",
    "    \"\"\"n-gram BLEU\n",
    "     gram: int [1-4]\n",
    "     return: float \n",
    "    \"\"\"\n",
    "    candidate = candidate.split(\" \")\n",
    "    reference = [reference.split(\" \")]\n",
    "    weights = [0, 0, 0, 0]\n",
    "    weights[gram - 1] = 1 \n",
    "    return sentence_bleu(reference, candidate, weights=weights) \n",
    "\n",
    "total = {\"bleu1\":[], \"bleu2\":[]}\n",
    "with open(meta, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.read().splitlines()\n",
    "    for line in lines:\n",
    "        if line.startswith('MV'):\n",
    "            name, text, transcript, bleu = line.split('|')\n",
    "            bleu = compute_bleu(transcript, text, gram=1)\n",
    "            total[\"bleu1\"].append(bleu)\n",
    "        elif line.startswith('SA'):\n",
    "            name, text, transcript, bleu = line.split('|')\n",
    "            bleu = compute_bleu(transcript, text, gram=1)\n",
    "            total[\"bleu2\"].append(bleu)\n",
    "            \n",
    "print(f\"Total bleu1: {sum(total['bleu1']) / len(total['bleu1'])}\")\n",
    "print(f\"Total bleu2: {sum(total['bleu2']) / len(total['bleu2'])}\")\n",
    "\n",
    "\"\"\"\n",
    "Total bleu1: 0.5347381994290764\n",
    "Total bleu2: 0.6913090188969255\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f915270",
   "metadata": {},
   "source": [
    "### Compute new BLEU with trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8611da2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v2.3.0-6-g23ad988\n",
      "DeepSpeech: v0.9.3-0-gf2e9c85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bleu1: 0.8120169619005472\n",
      "Total bleu2: 0.9720834323256764\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import deepspeech\n",
    "import pydub\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "class DeepSpeech:\n",
    "    def __init__(self, model, scorer, alpha=0.931289039105002, beta=1.1834137581510284):\n",
    "        self.model = deepspeech.Model(model)\n",
    "        self.model.enableExternalScorer(scorer)\n",
    "        self.model.setScorerAlphaBeta(alpha, beta)\n",
    "   \n",
    "    def transcribe(self, audio):\n",
    "        audio_segment = pydub.AudioSegment.from_wav(audio)\n",
    "        audio_segment = audio_segment.set_frame_rate(16000)\n",
    "        assert audio_segment.frame_rate == 16000 \n",
    "        samples = audio_segment.get_array_of_samples()\n",
    "        return self.model.stt(samples)\n",
    "\n",
    "def counter(num=1, length=3):\n",
    "    \"\"\"Counter etc. 0001, 0002\n",
    "    Attributes:\n",
    "    num (int) integer etc. 1 ==> 0001\n",
    "        length (int) length of counter etc. 3 ==> 001\n",
    "    Return:\n",
    "        (str) etc. 0001\n",
    "    \"\"\"\n",
    "    number = '0' * length + str(num)\n",
    "    number = number[len(number)-length:]\n",
    "    return number\n",
    "\n",
    "def compute_bleu(candidate, reference, gram=1):\n",
    "    candidate = candidate.split(\" \")\n",
    "    reference = [reference.split(\" \")]\n",
    "    weights = [0, 0, 0, 0]\n",
    "    weights[gram - 1] = 1 \n",
    "    return sentence_bleu(reference, candidate, weights=weights)     \n",
    "\n",
    "# PATHS\n",
    "model_path = 'model/output_graph.tflite'\n",
    "scorer_path = 'model/output_graph.scorer'\n",
    "base = \"/root/PycharmProjects/Tensorflow-2.X/07 - DeepSpeech Vad Transcriber + Create Wavs/audio/Good manners\"\n",
    "meta = f\"{base}/metadata.csv\"\n",
    "# VARIABLES\n",
    "total = {\"bleu1\":[], \"bleu2\":[]}\n",
    "model = DeepSpeech(model_path, scorer_path)\n",
    "\n",
    "with open(meta, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.read().splitlines()\n",
    "    for count, line in enumerate(lines, 1):\n",
    "        name, text, _, _ = line.split('|')\n",
    "        audio_path = f\"{base}/wavs/{name}.wav\"\n",
    "        transcript = model.transcribe(audio_path)\n",
    "        \n",
    "        if line.startswith('MV'):    \n",
    "            bleu = compute_bleu(transcript, text, gram=1)\n",
    "            total[\"bleu1\"].append(bleu)\n",
    "        elif line.startswith('SA'):\n",
    "            bleu = compute_bleu(transcript, text, gram=1)\n",
    "            total[\"bleu2\"].append(bleu)\n",
    "    \n",
    "        print(f\"\\rProcess: {counter(len(lines) - count, length=3)}\", end=\"\\r\")\n",
    "            \n",
    "            \n",
    "print(f\"Total bleu1: {sum(total['bleu1']) / len(total['bleu1'])}\")\n",
    "print(f\"Total bleu2: {sum(total['bleu2']) / len(total['bleu2'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1306e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff0545f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8b0059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defb2001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f6762e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
