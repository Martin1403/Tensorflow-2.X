{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdba5345",
   "metadata": {},
   "source": [
    "### Vad audio  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04e342cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- \\ | / - \\ | / - \\ | / - \\ | \r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import collections\n",
    "import queue\n",
    "import wave\n",
    "\n",
    "from halo import Halo\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "from scipy import signal\n",
    "import webrtcvad\n",
    "\n",
    "\n",
    "class Audio(object):\n",
    "    \"\"\"Streams raw audio from microphone. Data is received in a\n",
    "    separate thread, and stored in a buffer, to be read from.\"\"\"\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    # Network/VAD rate-space\n",
    "    RATE_PROCESS = 16000\n",
    "    CHANNELS = 1\n",
    "    BLOCKS_PER_SECOND = 50\n",
    "\n",
    "    def __init__(self, callback=None, device=None, input_rate=RATE_PROCESS, file=None):\n",
    "        def proxy_callback(in_data, frame_count, time_info, status):\n",
    "            # pylint: disable=unused-argument\n",
    "            if self.chunk is not None:\n",
    "                in_data = self.wf.readframes(self.chunk)\n",
    "            callback(in_data)\n",
    "            return (None, pyaudio.paContinue)\n",
    "\n",
    "        if callback is None:\n",
    "            callback = lambda in_data: self.buffer_queue.put(in_data)\n",
    "        self.buffer_queue = queue.Queue()\n",
    "        self.device = device\n",
    "        self.input_rate = input_rate\n",
    "        self.sample_rate = self.RATE_PROCESS\n",
    "        self.block_size = int(self.RATE_PROCESS / float(self.BLOCKS_PER_SECOND))\n",
    "        self.block_size_input = int(self.input_rate / float(self.BLOCKS_PER_SECOND))\n",
    "        self.pa = pyaudio.PyAudio()\n",
    "\n",
    "        kwargs = {\n",
    "            'format': self.FORMAT,\n",
    "            'channels': self.CHANNELS,\n",
    "            'rate': self.input_rate,\n",
    "            'input': True,\n",
    "            'frames_per_buffer': self.block_size_input,\n",
    "            'stream_callback': proxy_callback,\n",
    "        }\n",
    "\n",
    "        self.chunk = None\n",
    "        # if not default device\n",
    "        if self.device:\n",
    "            kwargs['input_device_index'] = self.device\n",
    "        elif file is not None:\n",
    "            self.chunk = 320\n",
    "            self.wf = wave.open(file, 'rb')\n",
    "\n",
    "        self.stream = self.pa.open(**kwargs)\n",
    "        self.stream.start_stream()\n",
    "\n",
    "    def resample(self, data, input_rate):\n",
    "        \"\"\"\n",
    "        Microphone may not support our native processing sampling rate, so\n",
    "        resample from input_rate to RATE_PROCESS here for webrtcvad and\n",
    "        deepspeech\n",
    "        Args:\n",
    "            data (binary): Input audio stream\n",
    "            input_rate (int): Input audio rate to resample from\n",
    "        \"\"\"\n",
    "        data16 = np.fromstring(string=data, dtype=np.int16)\n",
    "        resample_size = int(len(data16) / self.input_rate * self.RATE_PROCESS)\n",
    "        resample = signal.resample(data16, resample_size)\n",
    "        resample16 = np.array(resample, dtype=np.int16)\n",
    "        return resample16.tostring()\n",
    "\n",
    "    def read_resampled(self):\n",
    "        \"\"\"Return a block of audio data resampled to 16000hz, blocking if necessary.\"\"\"\n",
    "        return self.resample(data=self.buffer_queue.get(),\n",
    "                             input_rate=self.input_rate)\n",
    "\n",
    "    def read(self):\n",
    "        \"\"\"Return a block of audio data, blocking if necessary.\"\"\"\n",
    "        return self.buffer_queue.get()\n",
    "\n",
    "    def destroy(self):\n",
    "        self.stream.stop_stream()\n",
    "        self.stream.close()\n",
    "        self.pa.terminate()\n",
    "\n",
    "    frame_duration_ms = property(lambda self: 1000 * self.block_size // self.sample_rate)\n",
    "\n",
    "    def write_wav(self, filename, data):\n",
    "        # logging.info(\"write wav %s\", filename)\n",
    "        wf = wave.open(filename, 'wb')\n",
    "        wf.setnchannels(self.CHANNELS)\n",
    "        # wf.setsampwidth(self.pa.get_sample_size(FORMAT))\n",
    "        assert self.FORMAT == pyaudio.paInt16\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(self.sample_rate)\n",
    "        wf.writeframes(data)\n",
    "        wf.close()\n",
    "\n",
    "\n",
    "class VADAudio(Audio):\n",
    "    \"\"\"Filter & segment audio with voice activity detection.\"\"\"\n",
    "\n",
    "    def __init__(self, aggressiveness=3, device=None, input_rate=None, file=None):\n",
    "        super().__init__(device=device, input_rate=input_rate, file=file)\n",
    "        self.vad = webrtcvad.Vad(aggressiveness)\n",
    "\n",
    "    def frame_generator(self):\n",
    "        \"\"\"Generator that yields all audio frames from microphone.\"\"\"\n",
    "        if self.input_rate == self.RATE_PROCESS:\n",
    "            while True:\n",
    "                yield self.read()\n",
    "        else:\n",
    "            while True:\n",
    "                yield self.read_resampled()\n",
    "\n",
    "    def vad_collector(self, padding_ms=300, ratio=0.75, frames=None):\n",
    "        \"\"\"Generator that yields series of consecutive audio frames comprising each utterance, separated by yielding\n",
    "         a single None. Determines voice activity by ratio of frames in padding_ms. Uses a buffer to include padding_ms\n",
    "         prior to being triggered.\n",
    "            Example: (frame, ..., frame, None, frame, ..., frame, None, ...)\n",
    "                      |---utterance---|        |---utterance---|\n",
    "        \"\"\"\n",
    "        if frames is None: frames = self.frame_generator()\n",
    "        num_padding_frames = padding_ms // self.frame_duration_ms\n",
    "        ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
    "        triggered = False\n",
    "\n",
    "        for frame in frames:\n",
    "            if len(frame) < 640:\n",
    "                return\n",
    "\n",
    "            is_speech = self.vad.is_speech(frame, self.sample_rate)\n",
    "\n",
    "            if not triggered:\n",
    "                ring_buffer.append((frame, is_speech))\n",
    "                num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "                if num_voiced > ratio * ring_buffer.maxlen:\n",
    "                    triggered = True\n",
    "                    for f, s in ring_buffer:\n",
    "                        yield f\n",
    "                    ring_buffer.clear()\n",
    "\n",
    "            else:\n",
    "                yield frame\n",
    "                ring_buffer.append((frame, is_speech))\n",
    "                num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
    "                if num_unvoiced > ratio * ring_buffer.maxlen:\n",
    "                    triggered = False\n",
    "                    yield None\n",
    "                    ring_buffer.clear()\n",
    "\n",
    "\n",
    "def main(path):\n",
    "    vad_audio = VADAudio(aggressiveness=3,\n",
    "                         device=None,\n",
    "                         input_rate=16000,\n",
    "                         file=None)\n",
    "\n",
    "    frames = vad_audio.vad_collector()\n",
    "    spinner = Halo(spinner='line')\n",
    "    wav_data = bytearray()\n",
    "\n",
    "    for frame in frames:\n",
    "        if frame is not None:\n",
    "            if spinner:\n",
    "                spinner.start()\n",
    "            wav_data.extend(frame)\n",
    "        else:\n",
    "            if spinner:\n",
    "                spinner.stop()\n",
    "            if os.path.exists(path):\n",
    "                os.remove(path)\n",
    "            vad_audio.write_wav(path, wav_data)\n",
    "            wav_data = bytearray()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        audio_path = \"model/mysample.wav\"\n",
    "        main(audio_path)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cae1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
