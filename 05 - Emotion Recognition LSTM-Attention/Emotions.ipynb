{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d8f2ff8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Try pretrained model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57072dd7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Load model, tokenizer and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3381b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df = pd.read_csv('data/emotion.data.zip', compression='zip')\n",
    "\n",
    "base = os.path.abspath(os.path.dirname(__name__))\n",
    "\n",
    "# Load pretrained model\n",
    "model = tf.keras.models.load_model(f\"{base}/data/model_att_v1.h5\")\n",
    "\n",
    "# Load tokenizer.\n",
    "with open('data/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "# Load id2label dictionary.\n",
    "with open('data/id2label.pickle', 'rb') as handle:\n",
    "    id2label = pickle.load(handle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c42030",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Choose random text and label and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b522147",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im feeling really contented \n",
      "\n",
      "joy VS joy\n"
     ]
    }
   ],
   "source": [
    "max_length = 178\n",
    "trunc_type = \"post\"\n",
    "i = random.randint(0, len(df[\"text\"]) -1)\n",
    "\n",
    "sample_text = df[\"text\"][i]\n",
    "sample_label = df[\"emotions\"][i]\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences([sample_text])\n",
    "\n",
    "padded = pad_sequences(\n",
    "    sequences, \n",
    "    maxlen=max_length, \n",
    "    padding=trunc_type, \n",
    "    truncating=trunc_type\n",
    ")\n",
    "\n",
    "y_pred = model.predict(padded)\n",
    "print(sample_text,\"\\n\") \n",
    "print(f\"{sample_label} VS {id2label[np.argmax(y_pred)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76d02d76",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joy'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"there was a little cute dog.\"\n",
    "sequences = tokenizer.texts_to_sequences([text])\n",
    "\n",
    "padded = pad_sequences(\n",
    "    sequences, \n",
    "    maxlen=max_length, \n",
    "    padding=trunc_type, \n",
    "    truncating=trunc_type\n",
    ")\n",
    "\n",
    "id2label[np.argmax(model.predict(padded))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb5781c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Note:** Here you may put your own text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0361ce3c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c965136",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "seed = 1403\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f4233",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f2582",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/emotion.data.zip', compression='zip')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a43dc7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot counts of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eae593",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "df.emotions.value_counts().plot.bar()\n",
    "plt.title(\"count/class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cf83c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### WordCloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95066ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from data.utils import word_cloud\n",
    "\n",
    "X, y = df[\"text\"].values.tolist(), df[\"emotions\"].values.tolist()\n",
    "word_cloud(\" \".join(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df16c8b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tokenize, padding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8446f046",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from data.utils import hist_plot\n",
    "\n",
    "vocab_size = 10000\n",
    "embedding_dim = 100\n",
    "trunc_type = \"post\"\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# Saving tokenizer\n",
    "with open('data/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "max_length = max(list(map(len, sequences)))\n",
    "\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding=trunc_type)\n",
    "hist_plot(np.count_nonzero(padded, axis=1), \"Padded sentences\", \"Length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50864aee",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Process Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d8477a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from data.utils import pie_plot\n",
    "\n",
    "embedding_dim = 100\n",
    "\n",
    "label2id = {l: i for i, l in enumerate(set(y))}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# Saving id2label\n",
    "with open('data/id2label.pickle', 'wb') as handle:\n",
    "    pickle.dump(id2label, handle)\n",
    "\n",
    "y = tf.keras.utils.to_categorical(\n",
    "    [label2id[i] for i in y], \n",
    "    num_classes=len(label2id), \n",
    "    dtype='float32'\n",
    ")\n",
    "\n",
    "\n",
    "split = 0.33\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded, y, test_size=split)\n",
    "\n",
    "pie_plot(data=[len(x_train), len(x_test)], labels=['Train', 'Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce68b40",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ee7e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, Dropout, Dense, TimeDistributed,\n",
    "    Bidirectional, LSTM, Dot, Activation, Reshape\n",
    "    \n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "inputs = Input(shape=(max_length,), dtype='int32', name=\"inputs\")\n",
    "emb = Embedding(vocab_size, embedding_dim, input_length=max_length, name=\"embeddings\")(inputs)\n",
    "emb = Dropout(0.2)(emb)\n",
    "\n",
    "lstm = Bidirectional(LSTM(embedding_dim, return_sequences=True))(emb)\n",
    "lstm = Dropout(0.2)(lstm)\n",
    "\n",
    "att = TimeDistributed(Dense(1))(lstm)\n",
    "att = Reshape((max_length,))(att)\n",
    "att = Activation('softmax', name='att_vector')(att)\n",
    "att = Dot(axes=1, name=\"att_output\")([lstm, att])\n",
    "\n",
    "\n",
    "dense = Dense(embedding_dim, activation='relu')(att)\n",
    "outputs = Dense(len(label2id), activation='softmax', name=\"outputs\")(dense)\n",
    "\n",
    "model = Model(inputs, outputs, name=\"sematic_with_attention\")\n",
    "plot_model(model, \"model.png\", show_shapes=True, dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b587e802",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "callback = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"], \n",
    "    optimizer='adam'\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=100, \n",
    "    batch_size=64, \n",
    "    validation_data=(x_test, y_test), \n",
    "    callbacks=[callback]\n",
    ")\n",
    "\n",
    "\n",
    "model.save(\"data/model_att_v1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98864b66",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
